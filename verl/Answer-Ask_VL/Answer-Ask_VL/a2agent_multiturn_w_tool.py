# Copyright 2023-2025 SGLang Team
# Copyright Amazon.com, Inc. or its affiliates.
# Copyright 2025 Reallm Labs Ltd. or its affiliates
# Copyright 2025 ModelBest Inc. and/or its affiliates
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
Preprocess the Geometry3k dataset to parquet format
"""

import argparse
import os
import torch
import datasets

from verl.utils.hdfs_io import copy, makedirs

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--local_dir", default=None, help="The save directory for the preprocessed dataset.")
    parser.add_argument("--hdfs_dir", default=None)
    parser.add_argument("--local_dataset_path", default="/project/peilab/qjl/CODE/DATA/A2Agent_RL/", help="The local path to the raw dataset, if it exists.")
    parser.add_argument(
        "--local_save_dir",
        default="/project/peilab/qjl/CODE/verl/Answer-Ask_VL/a2agent",
        help="The save directory for the preprocessed dataset.",
    )

    args = parser.parse_args()
    local_dataset_path = args.local_dataset_path

    # data_source = "hiyouga/geometry3k"

    # if local_dataset_path is not None:
    #     dataset = datasets.load_dataset(local_dataset_path)
    # else:
    #     dataset = datasets.load_dataset(data_source)

    dataset = datasets.load_dataset(local_dataset_path)

    # Convert to a single dataset if it's a DatasetDict
    if isinstance(dataset, datasets.DatasetDict):
        # Assuming you want to work with a single split, e.g., "train"
        # Or you can concatenate all splits
        dataset = dataset["train"] if "train" in dataset else next(iter(dataset.values()))
    
    # Create train-test split indices
    dataset_size = len(dataset)
    indices = list(range(dataset_size))
    import random
    random.shuffle(indices)
    
    train_size = int(0.9 * dataset_size)
    train_indices = indices[:train_size]
    test_indices = indices[train_size:]
    
    # Select subsets using Hugging Face Dataset's select method
    train_dataset = dataset.select(train_indices)
    test_dataset = dataset.select(test_indices)

    SYSTEM_PROMPT="""You are an agent - please keep going until the user's query is completely resolved, before ending your turn and yielding back to the user. Only terminate your turn when you are sure that the problem is solved.

Solve the following problem step by step. In your reasoning process, if the answer cannot be determined, you can write Python code in a Sand_Box_Server to process the image/video via PIL/opencv/supervision/Matplotlib etc. and extract/visualize more information from it. The stdout and stderr content, along with the processed video/image generated by Sand_Box_Server  will be returned to better assist with the user query.

You MUST use the python tool to analyze or transform videos whenever it could improve your understanding. This includes but is not limited to 2D/3D Bounding box annotation, Keypoint annotation, Cuboid annotation, TimeLine annotation, time grounding, space grounding, spatio-temporal grounding, zooming in, rotating, adjusting contrast, isolating features, computing statistics via code, visualization via Matplotlib.

You MUST plan extensively before each function call, and reflect extensively on the outcomes of the previous function calls. DO NOT do this entire process by making function calls only, as this can impair your ability to solve the problem and think insightfully.

Python tool can help enhance your understanding of images/videos. Please use python flexibly in <code></code>code> XML tags. However, you can only call python tool to return one processed image/frame/clip/video in a single round; 

When reading images/videos in your Python code, always use the provided absolute paths. However, when saving output files, use relative paths only. Do not modify or reconstruct absolute paths. The Sand_Box_Server will provide the real absolute path for saved files. 

All your output should be in <think></think>, <answer></answer> or <code></code> XML tags."""

    # add a row to each data item that represents a unique id
    def make_map_fn(split):
        def process_fn(example, idx):
            problem = example.pop("problem")
            answer = example.pop("solution")
            video_path = example.pop("path")
            options = example.pop("options")
            problem_type = example.pop("problem_type")
            
            if len(options) > 0:
                problem += f" Options: {' '.join(options)}. This is a {problem_type} problem. "

            problem += (
                "You must give your answer in <answer></answer> XML tags. If you want python tool calling, give a estimated answer before <code></code>. "
                "Output format like <think></think><answer></answer> or <think></think><answer></answer><code></code>."
            )

            data = {
                "prompt": [
                    {
                        "role": "system",
                        "content": SYSTEM_PROMPT,
                    },
                    {
                        "role": "user",
                        "content": problem,
                    },
                ],
                "videos": ["/project/peilab/qjl/CODE/DATA/videos/"+video_path],
                "ability": "math",
                "reward_model": {"style": "rule", "ground_truth": answer},
                "extra_info": {
                    "split": split,
                    "index": idx,
                    "answer": answer,
                    "question": problem,
                    "need_tools_kwargs": True,
                    "tools_kwargs": {
                        "calc_a2agent_reward": {
                            "create_kwargs": {"ground_truth": answer},
                            # "execute_kwargs": {},
                            # "calc_reward_kwargs": {},
                            # "release_kwargs": {},
                        },
                    },
                },
            }
            return data

        return process_fn

    train_dataset = train_dataset.map(function=make_map_fn("train"), with_indices=True, num_proc=8)
    test_dataset = test_dataset.map(function=make_map_fn("test"), with_indices=True, num_proc=8)

    hdfs_dir = args.hdfs_dir
    local_save_dir = args.local_dir
    if local_save_dir is not None:
        print("Warning: Argument 'local_dir' is deprecated. Please use 'local_save_dir' instead.")
    else:
        local_save_dir = args.local_save_dir

    train_dataset.to_parquet(os.path.join(local_save_dir, "train.parquet"))
    test_dataset.to_parquet(os.path.join(local_save_dir, "test.parquet"))
    if hdfs_dir is not None:
        makedirs(hdfs_dir)
        copy(src=local_save_dir, dst=hdfs_dir)
